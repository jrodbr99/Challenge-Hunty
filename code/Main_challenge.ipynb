{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7a99e2-dda8-4338-9471-099a9ffd57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a588e7-5505-44c3-b3f5-3de072243c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('anonymized_collector_selector_data.json', 'r') as file:\n",
    "    collector_data = json.load(file)\n",
    "\n",
    "with open('anonymized_raw_conversations_data.json', 'r') as file:\n",
    "    raw_data = json.load(file)\n",
    "    \n",
    "num = 0\n",
    "\n",
    "candidates_id = [] # Save the candidates id into a list\n",
    "questions = []\n",
    "\n",
    "for key, value in collector_data.items():\n",
    "    candidates_id.append(str(key))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de64a201-c6e4-451f-8ce5-a1d98f9ddc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['673dc174bbdffa3d88a4c57a804781e98f86d00b730fa829d832b9753e7a3779',\n",
       " '5cd3713008635b158efa7406b25eabc6825e93a0625df6e96dd31aa9d857bb8e',\n",
       " '17fbd58ca771f94008ffb056f7226dde097a47039fb1ec9bf32872f0b6d20625',\n",
       " 'cee4404e5f694ad6141cb1dda30f78df1a5ed3e0efa6def532302a78a1ed26e8',\n",
       " '467b92deb304456a96d260db83d6fe421bcc30a5cf1113a7704de32a52301b10',\n",
       " '36f256f0c14392d372137b7874d33e347d0a948683093784dbbc3e49f02531de',\n",
       " 'cd00dc29b5c5e5fb660945d12255f9a110e4d643a73059fbae2f9335ce8b8264',\n",
       " '60d1a00ead883aaca3c501c309e2cbf685f1cd61435241b2faeb1f3db82f7541',\n",
       " '8e8aa543ee96e42cb85626d06d12995c5f93cf0b92057a946d53598e694d1990',\n",
       " '417c5647e0cc51c44517b7bb1a44ba32a98a6bc78d17db7deb540531c776a4b8',\n",
       " '2ef48296f91c4a0fa9e55128121dd1141c8ab9ce9d7b1696acbe3d7acd821684',\n",
       " 'b1eb364062dad98fbfa639a15f638f647b29fa286c5a9393244f4aa32ff3126a',\n",
       " '35e816d71c50d40dae1835d162ae6caf3e560c469809cc8b712d21e98906e457',\n",
       " 'e31768282dac1712c54f44dcdc6411aa1b027986a9c5616b635ba3d1799bd176',\n",
       " 'b4428b45723fa721ee1c54a3cf5d5b20d8955ed2282b37b8e06f39036492cf0b',\n",
       " 'fc66b1a85dbdee0d9245d418054a6ef357fd70dfadb1937ff85a51362d1fae99',\n",
       " '6030fc9319511735d269a158f7827f0ada85712190a7c72853d2239811f5b837',\n",
       " 'f60fcdfc553973d5505343d1d800c0352501d457eb95032e0fa6691d1c7cdfa4',\n",
       " '76b549982ebffdea760a51f343aff9fa5a18133f5d0b05a928cf2b833b253653',\n",
       " '0fadf8d7acd06b02dc37cdde4d06c67800b3fd9b0405a39f31f0495ee0ab6b47',\n",
       " '844783b6f673e3330748b1a80f0ae21b054dac2ba6a3e84e251890b0dbb7140f',\n",
       " 'dd05c95f3ce677fdaffb260f461216cae8d113c5f12f3e21e03b4e5281ff1504',\n",
       " 'b28d7dfffc0e9bafb9ace52b5481032f6dc955acb7b627a047e8d3e0ad7e8ff9',\n",
       " 'b90a13248ddd70fa0bc310abc10335e0623bd4668eae869169bb5effc8cb6344',\n",
       " '530fa2403330bbf327f64dd85157698267995166bef07f4e2fc96bcaf99ec2e4',\n",
       " '57226ac912d348dd7ceffc7ec6c8dcbe8291336bcca9f359107f89e3c6941464',\n",
       " 'd95946464034fcbf1114741016a50c42bf3fcc4aa2265e77b9e79d5a8dd12f0b',\n",
       " 'e94e705944bb7083b82165b56829817662852305c79b3eb7aff4aed7415d0e52',\n",
       " '975cb0b63b0b7e0550268d4678c1abce25e3d689c612e32cfc506c008ece8995']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acdcad85-abfc-4965-8e7f-ee75eae737b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "# Define an empty list or dictionaries to store the datasets\n",
    "datasets = []\n",
    "score =[]\n",
    "question_answer_lists = {}\n",
    "question_answer_listsencoded = {} # this one was created for keeping the altered answer and encoded answer separate\n",
    "discarded = []\n",
    "question_type = []\n",
    "question_idL = []\n",
    "conv_end = []\n",
    "\n",
    "# Iterate through each client dictionary in the collection_data\n",
    "first_dictionary = True  # Flag to check if it's the first dictionary\n",
    "for client_id, client_data in collector_data.items():\n",
    "  # Get the questions_answers dictionary\n",
    "    score.append(client_data[\"score\"])\n",
    "    discarded.append(client_data[\"discarded\"])   \n",
    "    conv_end.append(client_data[\"who_end_conversation\"])\n",
    "    for question_id, question_data in client_data[\"question_answers\"].items():\n",
    "        if question_id not in question_answer_lists:\n",
    "            question_answer_lists[question_id] = []\n",
    "            question_answer_listsencoded[question_id] = []\n",
    "        for key, value in question_data.items():\n",
    "            if key == \"answer\":\n",
    "                if value != \"No especificado\":\n",
    "                    value = \"Active response\"\n",
    "                question_answer_listsencoded[question_id].append(value)\n",
    "                question_answer_lists[question_id].append(value)\n",
    "        if first_dictionary == True and key == \"type\":\n",
    "            question_type.append(value)\n",
    "    first_dictionary = False  # Set flag to False after processing the first dictionary\n",
    "\n",
    "\n",
    "# getting the questions ids\n",
    "for key, data in question_answer_lists.items():\n",
    "    question_idL.append(key)\n",
    "                \n",
    "\n",
    "# creating the dataframes\n",
    "Candidatedf = pd.DataFrame()\n",
    "Candidatedf[\"candidates_id\"] = candidates_id\n",
    "\n",
    "\n",
    "\n",
    "Candidatedf[\"score\"] = score\n",
    "Candidatedf[\"discarded\"] = discarded\n",
    "Candidatedf[\"conversation_end\"] = conv_end\n",
    "\n",
    "print(len(Candidatedf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52176fa9-71e8-4ec4-b118-a647a54e8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of questions responded by candidate\n",
    "r_percan = []\n",
    "for candidate, responses in raw_data.items():\n",
    "    r_percan.append(len(responses))\n",
    "r_percan\n",
    "\n",
    "Candidatedf[\"total_conversation\"] = r_percan\n",
    "\n",
    "Candidatedf.head(6)\n",
    "Candidatedf.to_csv('Candidatedf.csv', index=False) \n",
    "\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "Candidatedf = Candidatedf.to_dict(orient='records')\n",
    "\n",
    "# Convert the list of dictionaries to JSON\n",
    "Candidatedf = json.dumps(Candidatedf)\n",
    "\n",
    "Candidatedf\n",
    "\n",
    "file_path = 'Candidatedf.json'\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json_file.write(Candidatedf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab5aa8e-f433-448d-9fad-e3948735863d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"question_id\":\"6b121e51865742678437cf22fdef67bb\",\"question_type\":\"Qualifying\"},{\"question_id\":\"8e39ba0b638a459aa5323aca5350f38c\",\"question_type\":\"Qualifying\"},{\"question_id\":\"92636148a4a04227ac2a17c744ae4aa9\",\"question_type\":\"Qualifying\"},{\"question_id\":\"92a6a5a99b694d398d1e591aaefe7558\",\"question_type\":\"Disqualifier\"},{\"question_id\":\"9cc0d3e4f0054d6a930cfcc20ca2cd5a\",\"question_type\":\"Informative\"},{\"question_id\":\"ff1d9a3711bc496c8a734171591a8fb7\",\"question_type\":\"Disqualifier\"}]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_df = pd.DataFrame()\n",
    "question_df[\"question_id\"] = question_idL\n",
    "question_df[\"question_type\"] = question_type\n",
    "\n",
    "question_df.to_csv('question_df.csv', index=False) \n",
    "\n",
    "\n",
    "question_df = question_df.to_json(orient='records')\n",
    "\n",
    "file_path = 'question_df.json'\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json_file.write(question_df)\n",
    "    \n",
    "question_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "330c113f-7aa1-41b8-8494-13ed3d6bc208",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_id=[]\n",
    "response=[]\n",
    "q_id = []\n",
    "for key, value in question_answer_listsencoded.items():\n",
    "    for x in range(len(value)):\n",
    "        c_id.append(candidates_id[x])\n",
    "        response.append(value[x])\n",
    "        q_id.append(key)\n",
    "            \n",
    "responses_df = pd.DataFrame()\n",
    "\n",
    "responses_df[\"candidates_id\"] = c_id\n",
    "responses_df[\"question_id\"] = q_id\n",
    "responses_df[\"response\"] = response\n",
    "\n",
    "responses_df\n",
    "responses_df.to_csv('responses_df.csv', index=False) \n",
    "\n",
    "\n",
    "responses_df = responses_df.to_json(orient='records')\n",
    "\n",
    "file_path = 'responses_df.json'\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json_file.write(responses_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db464ef-e290-4d52-ae54-b5ad9714b9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
